{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('fruit_veg_detection.h5')\n",
    "\n",
    "# Load the input image\n",
    "img = cv2.imread('test_image.jpg')\n",
    "\n",
    "# Preprocess the input image\n",
    "img = cv2.resize(img, (224, 224))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = img.astype('float32') / 255.0\n",
    "img = tf.expand_dims(img, axis=0)\n",
    "\n",
    "# Use the model to predict the classes of objects in the image\n",
    "preds = model.predict(img)[0]\n",
    "labels = ['apple', 'banana', 'orange', 'carrot', 'broccoli', 'pepper', 'tomato']\n",
    "class_indices = tf.argsort(preds, direction='DESCENDING')\n",
    "class_scores = tf.sort(preds, direction='DESCENDING')\n",
    "\n",
    "# Display the top 3 classes and their scores\n",
    "for i in range(3):\n",
    "    class_index = class_indices[i].numpy()\n",
    "    class_score = class_scores[i].numpy()\n",
    "    class_label = labels[class_index]\n",
    "    print(f\"{class_label}: {class_score:.2f}\")\n",
    "\n",
    "# Display the image with bounding boxes around the detected objects\n",
    "for i, pred in enumerate(preds):\n",
    "    if pred > 0.5:\n",
    "        label = labels[i]\n",
    "        (startX, startY, endX, endY) = boxes[i]\n",
    "        cv2.rectangle(img, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "        y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "        cv2.putText(img, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('Fruit and Vegetable Detection', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.004] global loadsave.cpp:244 findDecoder imread_('image.png.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /Users/opencv-cn/GHA-OCV-1/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/smooth.dispatch.cpp:617: error: (-215:Assertion failed) !_src.empty() in function 'GaussianBlur'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/Users/kemaldemirel/Desktop/Lectures/Bil 468/Project/Computer-Vision-Fruit-Vegetables-Detection/samples.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kemaldemirel/Desktop/Lectures/Bil%20468/Project/Computer-Vision-Fruit-Vegetables-Detection/samples.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39mimage.png.jpg\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kemaldemirel/Desktop/Lectures/Bil%20468/Project/Computer-Vision-Fruit-Vegetables-Detection/samples.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Define augmentations\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kemaldemirel/Desktop/Lectures/Bil%20468/Project/Computer-Vision-Fruit-Vegetables-Detection/samples.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m augmentations \u001b[39m=\u001b[39m [\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kemaldemirel/Desktop/Lectures/Bil%20468/Project/Computer-Vision-Fruit-Vegetables-Detection/samples.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     cv2\u001b[39m.\u001b[39mflip(img, \u001b[39m0\u001b[39m),     \u001b[39m# Vertical flip\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kemaldemirel/Desktop/Lectures/Bil%20468/Project/Computer-Vision-Fruit-Vegetables-Detection/samples.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     cv2\u001b[39m.\u001b[39mflip(img, \u001b[39m1\u001b[39m),     \u001b[39m# Horizontal flip\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kemaldemirel/Desktop/Lectures/Bil%20468/Project/Computer-Vision-Fruit-Vegetables-Detection/samples.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     cv2\u001b[39m.\u001b[39mflip(img, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m),    \u001b[39m# Both flips\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kemaldemirel/Desktop/Lectures/Bil%20468/Project/Computer-Vision-Fruit-Vegetables-Detection/samples.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     cv2\u001b[39m.\u001b[39mrotate(img, cv2\u001b[39m.\u001b[39mROTATE_90_CLOCKWISE),   \u001b[39m# Rotate 90 degrees clockwise\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kemaldemirel/Desktop/Lectures/Bil%20468/Project/Computer-Vision-Fruit-Vegetables-Detection/samples.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     cv2\u001b[39m.\u001b[39mrotate(img, cv2\u001b[39m.\u001b[39mROTATE_90_COUNTERCLOCKWISE),  \u001b[39m# Rotate 90 degrees counter-clockwise\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kemaldemirel/Desktop/Lectures/Bil%20468/Project/Computer-Vision-Fruit-Vegetables-Detection/samples.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     cv2\u001b[39m.\u001b[39mrotate(img, cv2\u001b[39m.\u001b[39mROTATE_180),    \u001b[39m# Rotate 180 degrees\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kemaldemirel/Desktop/Lectures/Bil%20468/Project/Computer-Vision-Fruit-Vegetables-Detection/samples.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     cv2\u001b[39m.\u001b[39;49mGaussianBlur(img, (\u001b[39m5\u001b[39;49m, \u001b[39m5\u001b[39;49m), \u001b[39m0\u001b[39;49m),  \u001b[39m# Apply Gaussian blur\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kemaldemirel/Desktop/Lectures/Bil%20468/Project/Computer-Vision-Fruit-Vegetables-Detection/samples.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     cv2\u001b[39m.\u001b[39mmedianBlur(img, \u001b[39m5\u001b[39m)             \u001b[39m# Apply median blur\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kemaldemirel/Desktop/Lectures/Bil%20468/Project/Computer-Vision-Fruit-Vegetables-Detection/samples.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kemaldemirel/Desktop/Lectures/Bil%20468/Project/Computer-Vision-Fruit-Vegetables-Detection/samples.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Apply augmentations\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kemaldemirel/Desktop/Lectures/Bil%20468/Project/Computer-Vision-Fruit-Vegetables-Detection/samples.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, a \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(augmentations):\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /Users/opencv-cn/GHA-OCV-1/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/smooth.dispatch.cpp:617: error: (-215:Assertion failed) !_src.empty() in function 'GaussianBlur'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('image.png.jpg')\n",
    "\n",
    "# Define augmentations\n",
    "augmentations = [\n",
    "    cv2.flip(img, 0),     # Vertical flip\n",
    "    cv2.flip(img, 1),     # Horizontal flip\n",
    "    cv2.flip(img, -1),    # Both flips\n",
    "    cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE),   # Rotate 90 degrees clockwise\n",
    "    cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE),  # Rotate 90 degrees counter-clockwise\n",
    "    cv2.rotate(img, cv2.ROTATE_180),    # Rotate 180 degrees\n",
    "    cv2.GaussianBlur(img, (5, 5), 0),  # Apply Gaussian blur\n",
    "    cv2.medianBlur(img, 5)             # Apply median blur\n",
    "]\n",
    "\n",
    "# Apply augmentations\n",
    "for i, a in enumerate(augmentations):\n",
    "    cv2.imshow(f\"Augmentation {i+1}\", a)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('fruit.jpg')\n",
    "\n",
    "# Convert image to HSV color space\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define lower and upper bounds for green color\n",
    "lower_green = np.array([36, 25, 25])\n",
    "upper_green = np.array([86, 255, 255])\n",
    "\n",
    "# Threshold the image to get only green color\n",
    "mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "\n",
    "# Find contours in the binary image\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw contours on the original image\n",
    "cv2.drawContours(img, contours, -1, (0, 0, 255), 2)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('Object Detection and Segmentation', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('watermelon.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "equalized = cv2.equalizeHist(gray)\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "normalized = clahe.apply(gray)\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Histogram Equalization', equalized)\n",
    "cv2.imshow('Contrast Normalization', normalized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('watermelon.jpg')\n",
    "\n",
    "# Apply Gaussian blur\n",
    "blurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "# Apply median blur\n",
    "median = cv2.medianBlur(img, 5)\n",
    "\n",
    "# Display the results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# İyi kod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def color_histogram(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hist = []\n",
    "    for i in range(3):\n",
    "        channel_hist, _ = np.histogram(hsv[:,:,i], bins=256, range=[0, 256])\n",
    "        hist.extend(channel_hist)\n",
    "    return hist\n",
    "\n",
    "def texture_analysis(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    kernel = cv2.getGaborKernel((21, 21), 4.0, np.pi/4, 6.0, 1.0, 0, cv2.CV_32F)\n",
    "    filtered = cv2.filter2D(img_gray, cv2.CV_8UC3, kernel)\n",
    "    mean, var = cv2.meanStdDev(filtered)\n",
    "    return np.concatenate([mean, var]).ravel()\n",
    "\n",
    "def edge_detection(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(img_gray, 100, 200)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_edges = len(contours)\n",
    "    edge_lengths = np.array([len(c) for c in contours])\n",
    "    edge_orientation_var = np.var([np.arctan2(c[0][1]-c[-1][1], c[0][0]-c[-1][0]) for c in contours])\n",
    "    return np.array([num_edges, np.mean(edge_lengths), np.var(edge_lengths), edge_orientation_var])\n",
    "\n",
    "# example usage\n",
    "img = cv2.imread('path/to/image.jpg')\n",
    "color_hist_features = color_histogram(img)\n",
    "texture_features = texture_analysis(img)\n",
    "edge_features = edge_detection(img)\n",
    "features = np.concatenate([color_hist_features, texture_features, edge_features])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Başka iyi kod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# feature extraction functions\n",
    "def color_histogram(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hist = []\n",
    "    for i in range(3):\n",
    "        channel_hist, _ = np.histogram(hsv[:,:,i], bins=256, range=[0, 256])\n",
    "        hist.extend(channel_hist)\n",
    "    return hist\n",
    "\n",
    "def texture_analysis(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    kernel = cv2.getGaborKernel((21, 21), 4.0, np.pi/4, 6.0, 1.0, 0, cv2.CV_32F)\n",
    "    filtered = cv2.filter2D(img_gray, cv2.CV_8UC3, kernel)\n",
    "    mean, var = cv2.meanStdDev(filtered)\n",
    "    return np.concatenate([mean, var]).ravel()\n",
    "\n",
    "def edge_detection(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(img_gray, 100, 200)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_edges = len(contours)\n",
    "    edge_lengths = np.array([len(c) for c in contours])\n",
    "    edge_orientation_var = np.var([np.arctan2(c[0][1]-c[-1][1], c[0][0]-c[-1][0]) for c in contours])\n",
    "    return np.array([num_edges, np.mean(edge_lengths), np.var(edge_lengths), edge_orientation_var])\n",
    "\n",
    "# Load the dataset\n",
    "dataset = []\n",
    "labels = []\n",
    "label_map = {'Apple': 0, 'Banana': 1, 'Orange': 2}\n",
    "for label, label_idx in label_map.items():\n",
    "    for i in range(1, 11):\n",
    "        img_path = f'path/to/dataset/{label}{i}.jpg'\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        features = np.concatenate([color_histogram(img), texture_analysis(img), edge_detection(img)])\n",
    "        dataset.append(features)\n",
    "        labels.append(label_idx)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a SVM classifier on the training set\n",
    "clf = SVC(kernel='linear', C=1.0, probability=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test set accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Save the trained model to disk\n",
    "import pickle\n",
    "with open('path/to/model.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "# Load the trained model and predict on a new image\n",
    "with open('path/to/model.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "img = cv2.imread('path/to/new/image.jpg')\n",
    "features = np.concatenate([color_histogram(img), texture_analysis(img), edge_detection(img)])\n",
    "label_idx = clf.predict(np.array([features]))\n",
    "label_map = {v: k for k, v in label_map.items()}\n",
    "label = label_map[label_idx[0]]\n",
    "print(f'Predicted label: {label}')\n",
    "\n",
    "# Draw the predicted label on the image\n",
    "cv2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAŞKA İYİ KOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "dataset_path = '/path/to/your/dataset'\n",
    "categories = os.listdir(dataset_path)\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for category in categories:\n",
    "    folder_path = os.path.join(dataset_path, category)\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        # Step 2: Preprocess the images\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img, (50, 50))\n",
    "        img = img / 255.0\n",
    "\n",
    "        # Step 3: Feature Extraction\n",
    "        hist = cv2.calcHist([img], [0], None, [256], [0, 256]).flatten()\n",
    "        data.append(hist)\n",
    "        labels.append(category)\n",
    "\n",
    "# Step 4: Train the model\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)\n",
    "\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Test the model\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(acc * 100))\n",
    "\n",
    "# Step 6: Deploy the model\n",
    "test_img_path = '/path/to/your/test/image'\n",
    "test_img = cv2.imread(test_img_path)\n",
    "\n",
    "test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "test_img = cv2.resize(test_img, (50, 50))\n",
    "test_img = test_img / 255.0\n",
    "\n",
    "test_hist = cv2.calcHist([test_img], [0], None, [256], [0, 256]).flatten()\n",
    "\n",
    "result = model.predict([test_hist])\n",
    "fruit = le.inverse_transform(result)[0]\n",
    "\n",
    "print(\"Detected Fruit: \", fruit)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1947ca4dac24bb13e7a62b4061f93f65a5b53851e3981a53736f1e8c5d59e7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
